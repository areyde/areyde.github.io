---
title: "Mellum: Production-Grade in-IDE Contextual Code Completion with Multi-File Project Understanding"
authors: '<i>Nikita Pavlichenko, Iurii Nazarov, Ivan Dolgov, Ekaterina Garanina, Dmitry Ustalov, Ivan Bondyrev, Kseniia Lysaniuk, Evgeniia Vu, Kirill Chekmenev, Joseph Shtok, Yaroslav Golubev, Anton Semenkin, and Uladzislau Sazanovich</i>'
status: "preprint"
collection: publications
permalink: /publications/2025-10-07-mellum
date: 2025-10-07
venue: "<b>arXiv</b>"
pdf: 'https://arxiv.org/abs/2510.05788'
data: 'https://huggingface.co/collections/JetBrains/mellum-68120b4ae1423c86a2da007a'
counter_id: 'P8'
abstract: "<p><b>Abstract</b>. We present the Mellum models family, open-weight code completion models designed for interactive use in JetBrains IDEs. Mellums have 4B parameters, adopt a Llama-style architecture, and are pre-trained on ~4T tokens of permissively licensed, multi-language code. Our studies show that (i) careful data curation and staged training significantly improve the model's quality, (ii) editor-critical capabilities such as context packing are necessary for high-quality suggestions, and (iii) a compact, task-focused model can meet the cost and latency constraints of interactive completion.</p><p>In the paper, we describe an end-to-end industrial pipeline for producing contextualized in-editor completion: disciplined data governance, multi-stage training that includes fill-in-the-middle and project context via supervised fine-tuning, and alignment via direct preference optimization using feedback from real-world scenarios. Our quality evaluations include both large-scale offline benchmarks and online telemetry from production deployments in JetBrains IDEs. Mellums are released under the Apache-2.0 license on HuggingFace, with a public model card providing a reproducible reference for practitioners. Our experience offers a pragmatic blueprint for taking a focused, open model from a research prototype to at scale production for hundreds of thousands of users.</p>"
---